{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud Detection & ML Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data Source: https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud/code\n",
    "- Transaction Data Simulator: https://fraud-detection-handbook.github.io/fraud-detection-handbook/Chapter_3_GettingStarted/SimulatedDataset.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Context\n",
    "It is important that credit card companies are able to recognize fraudulent credit card transactions so that customers are not charged for items that they did not purchase.\n",
    "\n",
    "#### Content\n",
    "- Transactions made by credit cards in September 2013 by European cardholders in two days.\n",
    "- There are 492 frauds out of 284,807 transactions. \n",
    "- The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "\n",
    "#### Pre-work\n",
    "It contains only numerical input variables which are the result of a PCA transformation. Features V1, V2, … V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. \n",
    "\n",
    "'Time' : contains the seconds elapsed between each transaction and the first transaction in the dataset. \n",
    "'Amount' : is the transaction Amount, this feature can be used for example-dependant cost-sensitive learning. \n",
    "'Class' : is the response variable and it takes value 1 in case of fraud and 0 otherwise.\n",
    "\n",
    "Given the class imbalance ratio, measuring the accuracy using the Area Under the Precision-Recall Curve (AUPRC) is recommended. Confusion matrix accuracy is not meaningful for unbalanced classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import data and necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.229658</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>1.202613</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167716</td>\n",
       "      <td>-0.270710</td>\n",
       "      <td>-0.154104</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>-0.257237</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.644269</td>\n",
       "      <td>1.417964</td>\n",
       "      <td>1.074380</td>\n",
       "      <td>-0.492199</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.428118</td>\n",
       "      <td>1.120631</td>\n",
       "      <td>-3.807864</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.943465</td>\n",
       "      <td>-1.015455</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.649709</td>\n",
       "      <td>-0.415267</td>\n",
       "      <td>-0.051634</td>\n",
       "      <td>-1.206921</td>\n",
       "      <td>-1.085339</td>\n",
       "      <td>40.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.894286</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>-0.113192</td>\n",
       "      <td>-0.271526</td>\n",
       "      <td>2.669599</td>\n",
       "      <td>3.721818</td>\n",
       "      <td>0.370145</td>\n",
       "      <td>0.851084</td>\n",
       "      <td>-0.392048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.268092</td>\n",
       "      <td>-0.204233</td>\n",
       "      <td>1.011592</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>-0.384157</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.142404</td>\n",
       "      <td>93.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.385050</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "5   2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
       "6   4.0  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n",
       "7   7.0 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n",
       "8   7.0 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n",
       "9   9.0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "5  0.260314 -0.568671  ... -0.208254 -0.559825 -0.026398 -0.371427 -0.232794   \n",
       "6  0.081213  0.464960  ... -0.167716 -0.270710 -0.154104 -0.780055  0.750137   \n",
       "7 -3.807864  0.615375  ...  1.943465 -1.015455  0.057504 -0.649709 -0.415267   \n",
       "8  0.851084 -0.392048  ... -0.073425 -0.268092 -0.204233  1.011592  0.373205   \n",
       "9  0.069539 -0.736727  ... -0.246914 -0.633753 -0.120794 -0.385050 -0.069733   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "5  0.105915  0.253844  0.081080    3.67      0  \n",
       "6 -0.257237  0.034507  0.005168    4.99      0  \n",
       "7 -0.051634 -1.206921 -1.085339   40.80      0  \n",
       "8 -0.384157  0.011747  0.142404   93.20      0  \n",
       "9  0.094199  0.246219  0.083076    3.68      0  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"creditcard.csv\")     \n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "# Class 1 signifies a fraudulent case. \n",
    "X = data.drop(\"Class\", axis=1)\n",
    "y = data[\"Class\"]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "# 20% of the data will be used for testing, and the remaining 80% will be used for training.\n",
    "# random_state = 10 ensures that the random number generator will start from the same point every time the code runs, producing the same sequence of random numbers.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Models\n",
    "1. Random Forest Classifier \n",
    "2. Gradient Boosting Machines (GBM)\n",
    "3. Support Vector Machines (SVM)\n",
    "4. Neural Network (can consider if the dataset is larger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Random Forest Classifier\n",
    "\n",
    "##### Features and Advantages:\n",
    "- Random Forest Classifier is an ensemble learning method used for classification tasks.\n",
    "- Constructs multiple decision trees during training, each trained on a random subset of the training data and features.\n",
    "- Diversity among trees reduces overfitting compared to individual trees.\n",
    "- Predictions are aggregated through majority voting or averaging.\n",
    "- Robust against overfitting and noise in data.\n",
    "- Capable of capturing complex relationships and patterns.\n",
    "- Highly interpretable due to feature importance analysis.\n",
    "\n",
    "##### Why is it useful for fraud detection?:\n",
    "- Widely used across various domains, including fraud detection.\n",
    "- Efficiently detects fraudulent activities by learning from diverse and complex data patterns.\n",
    "- Random Forest Classifier is a versatile and effective tool for classification tasks, particularly suitable for fraud detection applications due to its ability to handle complex data patterns and provide insights into feature importance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Train the random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=10)\n",
    "\n",
    "# n_estimators: Usually use k-fold cross validation to determine the values but for small to medium-sized datasets, 100 trees is sufficient to capture the underlying patterns in the data.\n",
    "# Model Performance with more trees: Increasing the number of trees can lead to better model performance up to a certain point. However, beyond a certain threshold, the improvement in performance may become marginal, and additional only incurs computational cost.\n",
    "\n",
    "# Train the model\n",
    "rf_classifier.fit(X_train, y_train)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Make predictions and evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[56867     1]\n",
      " [   17    77]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.99      0.82      0.90        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.99      0.91      0.95     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "Accuracy Score: 0.9996839998595555\n",
      "\n",
      "The model correctly predicted 56867 instances of the negative class.\n",
      "There was 1 instance where the model incorrectly predicted the positive class when it was actually negative.\n",
      "There were 19 instances where the model incorrectly predicted the negative class when it was actually positive.\n",
      "The model correctly predicted 75 instances of the positive class. \n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "rf_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "#[[TN FP]\n",
    "# [FN TP]]\n",
    "rf_conf_matrix = confusion_matrix(y_test, rf_pred)\n",
    "rf_classification = classification_report(y_test, rf_pred)\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(rf_conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(rf_classification)\n",
    "print(\"Accuracy Score:\",rf_accuracy)   \n",
    "\n",
    "analysis = '''\n",
    "The model correctly predicted 56867 instances of the negative class.\n",
    "There was 1 instance where the model incorrectly predicted the positive class when it was actually negative.\n",
    "There were 19 instances where the model incorrectly predicted the negative class when it was actually positive.\n",
    "The model correctly predicted 75 instances of the positive class. '''\n",
    "\n",
    "print(analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC Score: 0.9452166383068517\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Make predictions on the test set, predict probabilities for class 1\n",
    "rf_pred_proba = rf_classifier.predict_proba(X_test)[:, 1]  \n",
    "#typically focus on the probabilities corresponding to the positive class (class 1) because we want to assess confidence that an instance is from class 1(fraud).\n",
    "\n",
    "# Calculate the AUC-ROC score\n",
    "rf_auc_roc = roc_auc_score(y_test, rf_pred_proba)\n",
    "print(\"AUC-ROC Score:\", rf_auc_roc)\n",
    "# A score of 1 indicates a perfect classifier.\n",
    "# A score of 0.5 suggests the classifier is performing no better than random guessing.\n",
    "# A score above 0.5 indicates that the model is better than random guessing, with higher scores indicating better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Gradient Boosting Machines (GBM)\n",
    "\n",
    "##### Features and Advantages:\n",
    "- Gradient Boosting Machines (GBM) is a powerful ensemble learning technique used for classification and regression tasks.\n",
    "- It builds a strong predictive model by sequentially adding weak learners, typically decision trees, to the ensemble.\n",
    "- Unlike Random Forest, GBM builds trees sequentially, with each tree aiming to correct the errors made by the previous ones.\n",
    "- This iterative process allows GBM to focus more on difficult-to-predict instances, improving predictive accuracy.\n",
    "- GBM is particularly effective at capturing complex relationships and non-linear patterns in the data.\n",
    "- It handles both numerical and categorical features well and automatically selects the most informative features during training.\n",
    "- Additionally, GBM provides flexibility in hyperparameter tuning, allowing practitioners to optimize model performance for specific tasks.\n",
    "\n",
    "##### Why is it useful for fraud detection?:\n",
    "- GBM is widely used across various domains, including fraud detection.\n",
    "- It efficiently detects fraudulent activities by learning from diverse and complex data patterns.\n",
    "- Gradient Boosting Machines offer a flexible and powerful tool for classification tasks, especially when dealing with imbalanced datasets and complex fraud patterns. Its robustness, high predictive power, and interpretability make it well-suited for fraud detection applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Train the Gradient Boosting Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Create the Gradient Boosting Machines \n",
    "gbm_classifier = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=10)\n",
    "# Train the model\n",
    "gbm_classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Make predictions and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[56853    15]\n",
      " [   17    77]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.84      0.82      0.83        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.92      0.91      0.91     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "Accuracy Score: 0.9994382219725431\n",
      "AUC-ROC Score: 0.933837730227073\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "gbm_pred = gbm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "#[[TN FP]\n",
    "# [FN TP]]\n",
    "gbm_conf_matrix = confusion_matrix(y_test, gbm_pred)\n",
    "gbm_classification = classification_report(y_test, gbm_pred)\n",
    "gbm_accuracy = accuracy_score(y_test, gbm_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(gbm_conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(gbm_classification )\n",
    "print(\"Accuracy Score:\", gbm_accuracy)  \n",
    "\n",
    "# AUC-ROC Score\n",
    "gbm_pred_proba = gbm_classifier.predict_proba(X_test)[:, 1]\n",
    "gbm_auc_roc = roc_auc_score(y_test, gbm_pred_proba)\n",
    "print(\"AUC-ROC Score:\", gbm_auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Support Vector Machines (SVM)\n",
    "\n",
    "##### Features and Advantages:\n",
    "- Support Vector Machines (SVM) is a versatile supervised learning algorithm used for classification and regression tasks.\n",
    "- SVM works by finding the hyperplane that best separates the classes in the feature space while maximizing the margin between the classes.\n",
    "- This hyperplane is determined by support vectors, which are the closest data points to the decision boundary.\n",
    "- SVM can handle high-dimensional data effectively and is robust to overfitting, especially in cases with limited training data.\n",
    "- SVM can utilize different kernel functions, such as linear, polynomial, and radial basis function (RBF) kernels, to capture complex relationships between features.\n",
    "\n",
    "##### Why is it useful for fraud detection?:\n",
    "- SVM is widely used across various domains, including fraud detection.\n",
    "- It efficiently separates fraudulent transactions from legitimate ones, even in highly imbalanced datasets.\n",
    "- Support Vector Machines offer a flexible and powerful tool for fraud detection, particularly in scenarios where linear separation is not sufficient and complex decision boundaries are needed. Its robustness, scalability, and ability to handle high-dimensional data make it well-suited for fraud detection applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Train the Support Vector Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(probability=True, random_state=10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Step 1: Train the Support Vector Classifier\n",
    "svm_classifier = SVC(kernel='rbf', C=1.0, probability=True, random_state=10)\n",
    "\n",
    "# Train the model\n",
    "svm_classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Step 2: Make predictions and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yjkwak.2018\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\yjkwak.2018\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\yjkwak.2018\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[56868     0]\n",
      " [   94     0]]\n",
      "\n",
      "The SVM model correctly predicted 56868 instances of the negative class (non-fraudulent transactions) as true negatives.\n",
      "The model incorrectly predicted 94 instances of the positive class (fraudulent transactions) as false negatives.\n",
      "There were no instances predicted as false positives (fraudulent transactions incorrectly classified as non-fraudulent).\n",
      "There were no instances predicted as true positives (correctly classified as fraudulent transactions).\n",
      "\n",
      "This caused error in calculating precision and Fscore because  there are no predicted samples for the positive class\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.00      0.00      0.00        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.50      0.50      0.50     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "Accuracy Score: 0.9983497770443454\n",
      "AUC-ROC Score: 0.46449130423721074\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "svm_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "#[[TN FP]\n",
    "# [FN TP]]\n",
    "svm_conf_matrix = confusion_matrix(y_test, svm_pred)\n",
    "svm_classification = classification_report(y_test,svm_pred)\n",
    "svm_accuracy = accuracy_score(y_test,svm_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(svm_conf_matrix )\n",
    "\n",
    "svm_analysis = '''\n",
    "The SVM model correctly predicted 56868 instances of the negative class (non-fraudulent transactions) as true negatives.\n",
    "The model incorrectly predicted 94 instances of the positive class (fraudulent transactions) as false negatives.\n",
    "There were no instances predicted as false positives (fraudulent transactions incorrectly classified as non-fraudulent).\n",
    "There were no instances predicted as true positives (correctly classified as fraudulent transactions).\n",
    "\n",
    "This caused error in calculating precision and Fscore because  there are no predicted samples for the positive class\n",
    "'''\n",
    "\n",
    "print(svm_analysis)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(svm_classification)\n",
    "print(\"Accuracy Score:\", svm_accuracy)  \n",
    "\n",
    "# AUC-ROC Score\n",
    "svm_pred_proba = svm_classifier.predict_proba(X_test)[:, 1]\n",
    "svm_auc_roc = roc_auc_score(y_test, svm_pred_proba)\n",
    "print(\"AUC-ROC Score:\", svm_auc_roc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparisons\n",
    "Find the most suitable model to be used for this fraud detection modelling. \n",
    "\n",
    "- The classification report provides detailed information about precision, recall, F1-score, and other metrics for each class, helping to understand how well the model performs for different classes. \n",
    "- The confusion matrix gives a concise summary of correct and incorrect predictions, allowing for the analysis of specific types of errors made by the model. \n",
    "- Accuracy provides an overall measure of correct predictions, but it may not be sufficient, especially in the case of imbalanced datasets.\n",
    "- Additionally, the AUC-ROC Score evaluates the model's ability to discriminate between positive and negative classes across different thresholds, providing valuable insights into its performance. \n",
    "\n",
    "Considering multiple evaluation metrics provides a comprehensive understanding of the model's performance, aiding in informed decision-making and model refinement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model is Random Forest with Accuracy: 0.9996839998595555\n"
     ]
    }
   ],
   "source": [
    "#pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting the accuracy of each model\n",
    "models = ['Random Forest', 'Gradient Boosting', 'Support Vector Machines']\n",
    "accuracies = [rf_accuracy, gbm_accuracy, svm_accuracy]\n",
    "\n",
    "plt.bar(models, accuracies, color=['blue', 'green', 'red'], width=0.5)\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Comparison of Different Models')\n",
    "plt.ylim(0.99, 1.0)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Finding the best model based on accuracy\n",
    "best_model = max(zip(['Random Forest', 'Gradient Boosting', 'Support Vector Machines'], [rf_accuracy, gbm_accuracy, svm_accuracy]), key=lambda x: x[1])\n",
    "print(\"Best Model is\", best_model[0], \"with Accuracy:\", best_model[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Classifier Confusion Matrix:\n",
      "[[56867     1]\n",
      " [   17    77]]\n",
      "\n",
      "Gradient Boosting Machines Confusion Matrix:\n",
      "[[56853    15]\n",
      " [   17    77]]\n",
      "\n",
      "Support Vector Machines Confusion Matrix:\n",
      "[[56868     0]\n",
      " [   94     0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandom Forest Classifier Confusion Matrix:\")\n",
    "print(rf_conf_matrix)\n",
    "\n",
    "print(\"\\nGradient Boosting Machines Confusion Matrix:\")\n",
    "print(gbm_conf_matrix)\n",
    "\n",
    "print(\"\\nSupport Vector Machines Confusion Matrix:\")\n",
    "print(svm_conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model: Random Forest Classifier\n",
      "Confusion Matrix:\n",
      "[[56867     1]\n",
      " [   17    77]]\n"
     ]
    }
   ],
   "source": [
    "# Define the best model to be one with least number of FP & FN\n",
    "rf_fp_fn = rf_conf_matrix[0, 1] + rf_conf_matrix[1, 0]\n",
    "gbm_fp_fn = gbm_conf_matrix[0, 1] + gbm_conf_matrix[1, 0]\n",
    "svm_fp_fn = svm_conf_matrix[0, 1] + svm_conf_matrix[1, 0]\n",
    "\n",
    "# Return the index with the lowest sum of false positives and false negatives\n",
    "best_model_idx = min(range(3), key=lambda i: [rf_fp_fn, gbm_fp_fn, svm_fp_fn][i])\n",
    "\n",
    "# Print the confusion matrix of the best model\n",
    "if best_model_idx == 0:\n",
    "    print(\"\\nBest Model: Random Forest Classifier\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(rf_conf_matrix)\n",
    "elif best_model_idx == 1:\n",
    "    print(\"\\nBest Model: Gradient Boosting Machines\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(gbm_conf_matrix)\n",
    "else:\n",
    "    print(\"\\nBest Model: Support Vector Machines\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(svm_conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Classification Report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.99      0.82      0.90        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.99      0.91      0.95     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "\n",
      "Gradient Boosting Machines Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.84      0.82      0.83        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.92      0.91      0.91     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "\n",
      "Support Vector Machines Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56868\n",
      "           1       0.00      0.00      0.00        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.50      0.50      0.50     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report for Random Forest Classifier\n",
    "print(\"Random Forest Classifier Classification Report:\")\n",
    "print(rf_classification)\n",
    "\n",
    "# Print classification report for Gradient Boosting Machines\n",
    "print(\"\\nGradient Boosting Machines Classification Report:\")\n",
    "print(gbm_classification)\n",
    "\n",
    "# Print classification report for Support Vector Machines\n",
    "print(\"\\nSupport Vector Machines Classification Report:\")\n",
    "print(svm_classification)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 1\n",
      "Random Forest: 0.99, 0.82, 0.9\n",
      "Gradient Boosting: 0.84, 0.82, 0.83\n",
      "Support Vector Machines: 0.0, 0.0, 0.0\n",
      "Class: 0\n",
      "Random Forest: 1.0, 1.0, 1.0\n",
      "Gradient Boosting: 1.0, 1.0, 1.0\n",
      "Support Vector Machines: 1.0, 1.0, 1.0\n"
     ]
    }
   ],
   "source": [
    "# Parse precision, recall, and F1-score for each model\n",
    "def parse_classification_report(report):\n",
    "    lines = report.split('\\n')\n",
    "    data = {}\n",
    "    for line in lines[2:-5]:  # Skip header and footer lines\n",
    "        parts = line.split()\n",
    "        if len(parts) > 0:\n",
    "            class_name = parts[0]\n",
    "            precision = float(parts[1])\n",
    "            recall = float(parts[2])\n",
    "            f1_score = float(parts[3])\n",
    "            data[class_name] = {'precision': precision, 'recall': recall, 'f1-score': f1_score}\n",
    "    return data\n",
    "\n",
    "rf_metrics = parse_classification_report(rf_classification)\n",
    "gbm_metrics = parse_classification_report(gbm_classification)\n",
    "svm_metrics = parse_classification_report(svm_classification)\n",
    "\n",
    "# Compare precision, recall, and F1-score for each class\n",
    "classes = set(list(rf_metrics.keys()) + list(gbm_metrics.keys()) + list(svm_metrics.keys()))\n",
    "for class_name in classes:\n",
    "    print(f\"Class: {class_name}\")\n",
    "    print(f\"Random Forest: {rf_metrics.get(class_name, {}).get('precision', 0)}, {rf_metrics.get(class_name, {}).get('recall', 0)}, {rf_metrics.get(class_name, {}).get('f1-score', 0)}\")\n",
    "    print(f\"Gradient Boosting: {gbm_metrics.get(class_name, {}).get('precision', 0)}, {gbm_metrics.get(class_name, {}).get('recall', 0)}, {gbm_metrics.get(class_name, {}).get('f1-score', 0)}\")\n",
    "    print(f\"Support Vector Machines: {svm_metrics.get(class_name, {}).get('precision', 0)}, {svm_metrics.get(class_name, {}).get('recall', 0)}, {svm_metrics.get(class_name, {}).get('f1-score', 0)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare AUC-ROC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Classifier AUC-ROC Score: 0.9452166383068517\n",
      "Gradient Boosting Machines AUC-ROC Score: 0.933837730227073\n",
      "Support Vector Machines AUC-ROC Score: 0.46449130423721074\n"
     ]
    }
   ],
   "source": [
    "# Print AUC-ROC scores for all three models\n",
    "print(\"\\nRandom Forest Classifier AUC-ROC Score:\", rf_auc_roc)\n",
    "print(\"Gradient Boosting Machines AUC-ROC Score:\", gbm_auc_roc)\n",
    "print(\"Support Vector Machines AUC-ROC Score:\", svm_auc_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
